{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo los datos en un DataFrame\n",
    "df = pd.read_csv('03_data_procesada/01_data_pro_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defino variables predictoras y target del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['enginesize', 'curbweight', 'horsepower', 'carwidth', 'citympg', 'carlength']\n",
    "categorical_features = ['Brand', 'cylindernumber']\n",
    "\n",
    "predictors = ['enginesize', 'curbweight', 'horsepower', 'carwidth', 'citympg', 'carlength', 'Brand', 'cylindernumber']\n",
    "target = ['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dada la Importancia que definimos tiene la Marca en la Predicción, me encargo de que la cantidad de Datos por Marca (`Brand`) se equivalente tanto para Train como para Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(columns=predictors)\n",
    "X_train = pd.DataFrame(columns=predictors)\n",
    "y_test = pd.DataFrame(columns=target)\n",
    "y_train = pd.DataFrame(columns=target)\n",
    "\n",
    "brands = df['Brand'].unique()\n",
    "\n",
    "for brand in brands:\n",
    "    mask = df['Brand'] == brand\n",
    "    X_brand = df.loc[mask][predictors]\n",
    "    y_brand = df.loc[mask][target]\n",
    "    if len(X_brand) > 1:\n",
    "        X_brand_train, X_brand_test, y_brand_train, y_brand_test = train_test_split(X_brand, y_brand, test_size=0.5, random_state=42)\n",
    "    else:\n",
    "        X_brand_train = X_brand\n",
    "        X_brand_test = X_brand\n",
    "        y_brand_train = y_brand\n",
    "        y_brand_test = y_brand    \n",
    "    \n",
    "    X_train = pd.concat([X_train, X_brand_train], axis=0)\n",
    "    X_test = pd.concat([X_test, X_brand_test], axis=0)\n",
    "    y_train = pd.concat([y_train, y_brand_train], axis=0)\n",
    "    y_test = pd.concat([y_test, y_brand_test], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Crear el preprocesador para las variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear el pipeline del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', XGBRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurar la Grilla\n",
    "- `n_estimators`: Número de árboles en el modelo.\n",
    "- `learning_rate`: Tasa de aprendizaje.\n",
    "- `max_depth`: Profundidad máxima de cada árbol.\n",
    "- `subsample`: Proporción de muestras utilizadas para entrenar cada árbol.\n",
    "- `colsample_bytree`: Proporción de características utilizadas para entrenar cada árbol.\n",
    "- `gamma`: Reducción mínima de pérdida requerida para hacer una partición adicional en un nodo de árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aca se jugo con muchas combinaciones pero deje la combinación que mejor resultado arrojó\n",
    "\n",
    "param_grid = {\n",
    "    \"regressor__n_estimators\": [170],\n",
    "    \"regressor__learning_rate\": [0.11],\n",
    "    \"regressor__max_depth\": [5],\n",
    "    \"regressor__subsample\": [0.75],\n",
    "    \"regressor__colsample_bytree\": [0.65],\n",
    "    \"regressor__gamma\": [1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    model, param_grid, cv=5, scoring=\"neg_mean_squared_error\", n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Entrenar y evaluar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor combinación de hiperparámetros: {'regressor__colsample_bytree': 0.65, 'regressor__gamma': 1, 'regressor__learning_rate': 0.11, 'regressor__max_depth': 5, 'regressor__n_estimators': 170, 'regressor__subsample': 0.75}\n",
      "RMSE con mejores hiperparámetros: 2319.858632318536\n",
      "MSE con mejores hiperparámetros: 5381744.073942827\n",
      "R² con mejores hiperparámetros: 0.9188436269760132\n",
      "**************************************************\n",
      "R² del Train: 0.9995906949043274\n",
      "RMSE del Train: 156.43241857824626\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Aca se entrena el Modelo con Todas las combinaciones que se establezcan en la Grilla\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mejor combinación de hiperparámetros\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Mejor combinación de hiperparámetros: {best_params}\")\n",
    "\n",
    "# Evaluar el modelo con los mejores hiperparámetros --> best_model es la Variable que contendrá el Modelo Entrenado\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "best_mse = mean_squared_error(y_test, y_pred_best)\n",
    "best_r2 = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(f\"RMSE con mejores hiperparámetros: {np.sqrt(best_mse)}\")\n",
    "print(f\"MSE con mejores hiperparámetros: {best_mse}\")\n",
    "print(f\"R² con mejores hiperparámetros: {best_r2}\")\n",
    "\n",
    "# ******************************\n",
    "print('*'*50)\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "print(f\"R² del Train: {r2_score(y_train, y_pred_train)}\")\n",
    "print(f\"RMSE del Train: {np.sqrt(mean_squared_error(y_train, y_pred_train))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Toca Ahora crear una Medicion Propia mas entendible a lo que estamos estudiando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────┬───────────┬──────────────────┬─────────────────────┐\n",
      "│ y_test  │  y_pred   │    Diferencia    │     Porcentaje      │\n",
      "│ double  │   float   │      double      │       double        │\n",
      "├─────────┼───────────┼──────────────────┼─────────────────────┤\n",
      "│ 13495.0 │   13314.8 │   180.2001953125 │               -1.34 │\n",
      "│ 16500.0 │   13314.8 │  3185.2001953125 │               -19.3 │\n",
      "│ 13950.0 │   10354.9 │   3595.099609375 │              -25.77 │\n",
      "│ 17450.0 │  16067.71 │  1382.2900390625 │  -7.920000000000001 │\n",
      "│ 23875.0 │ 20309.777 │    3565.22265625 │              -14.93 │\n",
      "│ 15250.0 │ 12192.531 │       3057.46875 │              -20.05 │\n",
      "│ 16925.0 │ 10585.957 │    6339.04296875 │              -37.45 │\n",
      "│ 30760.0 │  37469.81 │   -6709.80859375 │               21.81 │\n",
      "│ 16430.0 │ 10585.957 │    5844.04296875 │              -35.57 │\n",
      "│ 36880.0 │  41983.44 │   -5103.44140625 │               13.84 │\n",
      "│     ·   │      ·    │          ·       │                  ·  │\n",
      "│     ·   │      ·    │          ·       │                  ·  │\n",
      "│     ·   │      ·    │          ·       │                  ·  │\n",
      "│  7775.0 │   8064.69 │ -289.68994140625 │                3.73 │\n",
      "│  9980.0 │ 10685.591 │  -705.5908203125 │                7.07 │\n",
      "│  9495.0 │  8461.702 │  1033.2978515625 │ -10.879999999999999 │\n",
      "│  7995.0 │   8064.69 │  -69.68994140625 │  0.8699999999999999 │\n",
      "│ 18950.0 │ 17985.271 │    964.728515625 │               -5.09 │\n",
      "│ 12940.0 │ 15708.992 │    -2768.9921875 │                21.4 │\n",
      "│ 22470.0 │ 17001.309 │    5468.69140625 │              -24.34 │\n",
      "│ 22625.0 │  18394.56 │   4230.439453125 │               -18.7 │\n",
      "│ 15985.0 │ 16491.748 │   -506.748046875 │                3.17 │\n",
      "│ 13415.0 │ 16521.006 │  -3106.005859375 │  23.150000000000002 │\n",
      "├─────────┴───────────┴──────────────────┴─────────────────────┤\n",
      "│ 109 rows (20 shown)                                4 columns │\n",
      "└──────────────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicciones = best_model.predict(X_test)\n",
    "\n",
    "resultados = pd.DataFrame()\n",
    "resultados['y_test'] = y_test\n",
    "resultados['y_pred'] = predicciones\n",
    "resultados['Diferencia'] = resultados['y_test'] - resultados['y_pred']\n",
    "resultados['Porcentaje'] = round((resultados['y_pred'] / resultados['y_test'] - 1),4) * 100\n",
    "\n",
    "duckdb.sql(\"\"\"SELECT * FROM resultados;\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos la Sumatoria de los Valores Absolutos de los errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────────────────┐\n",
       "│ sum(abs(Porcentaje)) │\n",
       "│        double        │\n",
       "├──────────────────────┤\n",
       "│              1373.13 │\n",
       "└──────────────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.sql(\"\"\"SELECT SUM(ABS(Porcentaje)) FROM resultados;\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos la media del error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promedio = round((1373.13/ resultados.shape[0]),2)\n",
    "promedio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Total hay una media de 12,6 % de error entre el Valor Predicho y la realidad de los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "Guardando el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/modelo_proyecto_02.pkl']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_model, 'models/modelo_proyecto_02.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "Preparandonos para trabajar en la App <br>\n",
    "Valores que pueden adoptar las distintas Predictoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enginesizes = [61, 326]       #Valor Minimo y Valor Maximo\n",
    "curbweights = [1488, 4066]    #Valor Minimo y Valor Maximo  \n",
    "citympgs = [13, 49]           #Valor Minimo y Valor Maximo\n",
    "carlenght = [141.1, 208.1]    #Valor Minimo y Valor Maximo\n",
    "horspowers = [48, 288]        #Valor Minimo y Valor Maximo\n",
    "carwidths = [60.3, 72.3]      #Valor Minimo y Valor Maximo      \n",
    "brands = ['Bmw', 'Volvo', 'Plymouth', 'Mitsubishi', 'Buick', 'Subaru', 'Volkswagen', 'Toyota', 'Jaguar', 'Dodge', 'Mazda',\n",
    "          'Porsche', 'Alfa-romeo', 'Audi', 'Nissan', 'Isuzu', 'Chevrolet', 'Mercury', 'Saab', 'Renault', 'Peugeot', 'Honda']\n",
    "cylindernumbers = ['two',  'three', 'four', 'five', 'six', 'eight', 'twelve']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# Como se Probaría el Modelo en la App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de Prueba en un diccionario y creamos el Dataframe de Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictors = ['enginesize', 'curbweight', 'horsepower', 'carwidth', 'citympg', 'carlength', 'Brand', 'cylindernumber']\n",
    "inputs = {\n",
    "    'enginesize': 209, \n",
    "    'curbweight': 2548, \n",
    "    'horsepower': 182, \n",
    "    'carwidth': 66.9, \n",
    "    'citympg': 16, \n",
    "    'carlength': 189.0, \n",
    "    'Brand': 'Bmw', \n",
    "    'cylindernumber': 'six'\n",
    "}\n",
    "\n",
    "# inputs_list  = [120,3095,97,65.2,27,173.4, \"Nissan\", \"four\"]\n",
    "valores_test = pd.DataFrame(inputs, index=[0])\n",
    "valores_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_cargado = joblib.load('models/modelo_proyecto_02.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32532.252"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediccion = modelo_cargado.predict(valores_test)\n",
    "prediccion[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "Preparando la data de la tabla de la app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargaremos una Data de Ejemplo que tendra 2 registros por Marca para que sean Datos de Prueba de la App\n",
    "tabla = pd.DataFrame(columns=df.columns)\n",
    "brands = df['Brand'].unique()\n",
    "\n",
    "for brand in brands:\n",
    "    mask = df['Brand'] == brand\n",
    "    if len(df.loc[mask]) > 1:\n",
    "        temporal = df.loc[mask].sample(n=2)\n",
    "    else: \n",
    "        temporal = df.loc[mask]  \n",
    "    tabla = pd.concat([tabla, temporal], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvamos la Data de Ejemplo que utilizaremos en la App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla = tabla[predictors + ['price']]\n",
    "\n",
    "tabla.to_csv('04_data_ejemplo_tabla_app/tabla_proj_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_modulo6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
